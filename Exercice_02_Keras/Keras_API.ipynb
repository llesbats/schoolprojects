{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWuH0ZW2JXX4"
   },
   "source": [
    "# Classification d'images avec *tf.keras*\n",
    "\n",
    "Dans ce projet, vous allez implémenter des réseaux neuronaux en utilisant les API de Keras.\n",
    "Nous utiliserons l'implémentation de Keras contenu dans TensorFlow, *tf.keras*.\n",
    "\n",
    "Lien vers la documentation de [keras.io](https://keras.io/).\n",
    "\n",
    "Tout le code que nous écrirons dans ce notebook fonctionnera avec la librairie Keras. Nous n'utiliserons pas de lignes spécifiques à TensorFlow.\n",
    "\n",
    "Pour rappel : la seule différence entre la librairie Keras et le Keras inclus dans TensorFlow est la façon d'importer Keras :\n",
    "\n",
    "```python\n",
    "# keras.io code:\n",
    "from keras.layers import Dense\n",
    "output_layer = Dense(10)\n",
    "\n",
    "# corresponding tf.keras code:\n",
    "from tensorflow.keras.layers import Dense\n",
    "output_layer = Dense(10)\n",
    "\n",
    "# or:\n",
    "from tensorflow import keras\n",
    "output_layer = keras.layers.Dense(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnvE4gHBJXX8"
   },
   "source": [
    "#◢  Import & Vérification des versions des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDs4gtdfJXX9"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5arxEGTVJXYC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras  # tf.keras\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66EAwUnfJXYG"
   },
   "outputs": [],
   "source": [
    "print(\"python\", sys.version)\n",
    "for module in tf, keras, pd, np, mpl:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDFQLo6fJXYJ"
   },
   "outputs": [],
   "source": [
    "assert sys.version_info >= (3, 5) # Python ≥3.5 required\n",
    "assert tf.__version__ >= \"2.0\"    # TensorFlow ≥2.0 required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2muDbRUJXYM"
   },
   "source": [
    "#◢  Chargement du jeu de données MNIST\n",
    "\n",
    "Keras permet de charger de nombreux datasets avec `keras.datasets`.\n",
    "Nous utiliserons le jeu de données MNIST *Modifier ou Mixed National Institute of Standards and Technology*, qui est une base de données de chiffres manuscrits.\n",
    "\n",
    "\n",
    "La base MNIST est devenu un test standard. Elle regroupe 60000 images d'apprentissage et 10000 images de test, issues d'une base de données antérieure, appelée simplement NIST1. \n",
    "Ces images sont en noir et blanc, normalisées centrées et de 28 pixels de côté.\n",
    "\n",
    "Pour l’historique de la création de cette base, voir [Yann LeCun](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "Séparez le jeu de données d'entrainement en :\n",
    "- un jeu de validation contenant 5000 images\n",
    "- un jeu d'entrainement contenant 55000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EetAUOJPJXYN"
   },
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# TODO Compléter\n",
    "X_valid, X_train = X_train_full[:XXX], X_train_full[XXX:]\n",
    "y_valid, y_train = y_train_full[:XXX], y_train_full[XXX:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3R5BBPoJXYQ"
   },
   "source": [
    "#◢  Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heInchNIJXYQ"
   },
   "source": [
    "Nous avons désormais 3 jeux de données :\n",
    "- Le jeu de données d'entrainement qui contient 55000 images de tailles 28x28 pixels\n",
    "- Le jeu de données de validation qui contient 5000 images de tailles 28x28 pixels\n",
    "- Le jeu de données de test qui contient 10000 images de tailles 28x28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uGU6211JXYR"
   },
   "outputs": [],
   "source": [
    "# TODO Afficher la taille du X_train\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYKLT2MJi47U"
   },
   "outputs": [],
   "source": [
    "# TODO Afficher la taille du X_valid\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEbrE_Csi5Hz"
   },
   "outputs": [],
   "source": [
    "# TODO Afficher la taille du X_test\n",
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86ync6j5JXYU"
   },
   "source": [
    "Chaque pixel a une valeur comprise entre 0 et 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSz9yXG1JXYV"
   },
   "outputs": [],
   "source": [
    "X_train[0][10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzmW71hFJXYX"
   },
   "source": [
    "Nous pouvons afficher une image en utilisant la fonction de Matplotlib `imshow()`, avec la carte des couleurs `'binary'` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNfTlmzKJXYY"
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[1], cmap=\"binary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTIADpMoJXYb"
   },
   "source": [
    "Les labels sont des classes allant de 0 à 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ME6F0R5oJXYb"
   },
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX5bTZD0JXYe"
   },
   "source": [
    "Regardons quelques images du jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwF7rb7oJXYf"
   },
   "outputs": [],
   "source": [
    "n_rows = 5\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols*2, n_rows*2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(XXX)\n",
    "        plt.axis('off')\n",
    "        plt.title('Chiffre ' + str(y_train[index]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9W4nc7QJXYh"
   },
   "source": [
    "#◢  Pré-Processing\n",
    "Les images étant dans l'échelle [grayscale](https://en.wikipedia.org/wiki/Grayscale), les valeurs varient de 0 à 255.\n",
    "\n",
    "Afin de normaliser (centrer) les données, nous allons implémnter la fonction Min-Max scaling dans la fonction `normalize_grayscale()`. Après la mise à l'échelle, les valeurs des pixels des données d'entrée iront de 0.1 à 0.9.\n",
    "\n",
    "Min-Max Scaling:\n",
    "$\n",
    "X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiTaO2ojDR8l"
   },
   "source": [
    "<img class=\"tfo-display-only-on-site\" src=\"http://datactik.com/other/Mean_Variance_Image.png\" height=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1R6KJirAJXYi"
   },
   "outputs": [],
   "source": [
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Min-Max scaling for grayscale image data\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    XXX\n",
    "    return XXX\n",
    "\n",
    "\n",
    "### VERIFIER VOTRE IMPLEMENTATION AVEC LES TESTS UNITAIRES CI-DESSOUS ###\n",
    "# Test Cases\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 255])),\n",
    "    [0.1, 0.103137254902, 0.106274509804, 0.109411764706, 0.112549019608, 0.11568627451, 0.118823529412, 0.121960784314,\n",
    "     0.125098039216, 0.128235294118, 0.13137254902, 0.9],\n",
    "    decimal=3)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 10, 20, 30, 40, 233, 244, 254,255])),\n",
    "    [0.1, 0.103137254902, 0.13137254902, 0.162745098039, 0.194117647059, 0.225490196078, 0.830980392157, 0.865490196078,\n",
    "     0.896862745098, 0.9])\n",
    "\n",
    "\n",
    "train_features = normalize_grayscale(X_train)\n",
    "val_features = normalize_grayscale(X_valid)\n",
    "test_features = normalize_grayscale(X_test)\n",
    "\n",
    "print('Tests Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vC2lvBnNJXYk"
   },
   "source": [
    "#◢  Construction d'un modèle \n",
    "\n",
    "Construction d'un modèle `Sequential` avec l'API `keras.models.Sequential`, sans aucun argument, et avec 3 couches en utilisant la méthode `add()` :\n",
    "  * Une couche `Flatten` (`keras.layers.Flatten`) pour convertir chaque image de taille 28x28 image en un simple tableau de 784 pixels. Comme cette couche est la première de votre modèle, vous devez spécifier l'argument `input_shape`.\n",
    "  * Une couche `Dense` (`keras.layers.Dense`) avec 50 neurones (également appelés units), et la fonction d'activation `\"relu\"`.\n",
    "  * Pour finir une couche `Dense` avec 10 neurones (1 par classe), et avec la fonction d'activation `\"softmax\"` activation pour s'assurer que la somme de toutes les probabilités des classe estimées pour chaque image est égale à 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGG516sJJXYl"
   },
   "outputs": [],
   "source": [
    "# TODO Construire le modèle\n",
    "model = XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4TeN71LJXYo"
   },
   "source": [
    "Vous pouvez également utiliser une autre annotation.\n",
    "Au lieu d'utiliser la méthode `add()`, vous pouvez lister les couches dans le constructeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgjvGcajJXYp"
   },
   "outputs": [],
   "source": [
    "# TODO Construire le modèle en utilisant add\n",
    "model = XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQLICr8JJXYs"
   },
   "source": [
    "Utilisez l'attribut `layers` de model pour afficher la liste des couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBzN-R23JXYt"
   },
   "outputs": [],
   "source": [
    "# TODO Afficher la liste des layers\n",
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2QVrm2rJXYu"
   },
   "source": [
    "Appelez la méthode `summary()` sur le model pour XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHGst-pXJXYv"
   },
   "outputs": [],
   "source": [
    "# TODO Summary\n",
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7WSu1YtJXYx"
   },
   "source": [
    "#◢  Compilation du modèle\n",
    "\n",
    "Après avoir créé le modèle, vous devez appeler la méthode `compile()`afin de spécifier la fonction de cout (`loss` function) et l'`optimizer` à utiliser. \n",
    "\n",
    "Dans ce TP, nous utiliserons la fonction de cout `\"sparse_categorical_crossentropy\"`, et l'optimiseur suivant `keras.optimizers.SGD(lr=0.01)`(stochastic gradient descent avec un learning rate à 0.01).\n",
    "\n",
    "Vous pouvez également spécifier une liste de métriques additionelles qui pourront être mesurée lors de la phase d'apprentissage comme `metrics=[\"accuracy\"]`. \n",
    "\n",
    "**Note**: Dans la documenation de Keras, vous trouverez d'autres fontions de cout `keras.losses`, d'autres métriques `keras.metrics` et d'autres optimiseurs `keras.optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xetpm-WFJXYx"
   },
   "outputs": [],
   "source": [
    "# TODO Compilation\n",
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_nJmnSiJXY0"
   },
   "source": [
    "#◢  Entrainement du modèle\n",
    "\n",
    "Votre modèle est désormais prêt à être entrainé. Appelez la méthode `fit()`, en passant les paramètres d'entrées (`train_features`) et les valeurs à prédire (`y_train`).\n",
    "\n",
    "Définissez :\n",
    "- le nombre d'epochs `epochs=5`\n",
    "- les données de validation `validation_data=(val_features, y_valid)`\n",
    "\n",
    "**Note**: La méthode `fit()` retourne un objet `History` qui contient les statistiques d'entrainement. N'oubliez pas de récupérer cet objet (`history = model.fit(...)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJV1ctEqJXY0"
   },
   "outputs": [],
   "source": [
    "# TODO Fit\n",
    "XXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQ5o3ptgJXY2"
   },
   "source": [
    "Regardons les valeurs de la fonction de cout et de l'accuracy sur les 2 jeux de données (train et validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGEselIGJXY3"
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obsCVKkeJXY5"
   },
   "outputs": [],
   "source": [
    "# TODO Plot de l'historique\n",
    "plot_learning_curves(XXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT44N9UgJXY6"
   },
   "source": [
    "Relancez `model.fit()` avec 3 epochs, que se passe-t-il ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQts_qH3JXY7"
   },
   "outputs": [],
   "source": [
    "# TODO Fit\n",
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhQCHGfVJXY9"
   },
   "source": [
    "#◢  Evaluation du modèle\n",
    "Appelez la méthode `evaluate()` sur le modèle précédement créé sur le jeu de données de test (`test_features` et `y_test`). Cette méthode va calculer la fonction de cout (ici cross-entropy) sur le jeu de test, ainsi que les métriques additionnelles (dans ce cas, l'accuracy). \n",
    "\n",
    "Votre modèle doit atteindre une accuracy de plus de 90% sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ym2wJr6kJXY-"
   },
   "outputs": [],
   "source": [
    "# TODO Evaluate\n",
    "XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oULxuai7JXY_"
   },
   "source": [
    "#◢  Prédiction\n",
    "Appelez la méthode `predict()` sur le modèle afin d'estimer la probabilité de chaque classe pour chaque instance (pour une meilleure lisibilité, utilisez la méthode `round()` sur les probabilités générées):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_9GWhVDJXZA"
   },
   "outputs": [],
   "source": [
    "# TODO Predict + Round\n",
    "y_proba = XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfIek4fhJXZC"
   },
   "source": [
    "A partir des probabilités des différentes valeurs, déduisons-en la valeur prédite (celle qui a le % maximum => utilisez la fonction `argmax`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hy1Szri6JXZD"
   },
   "outputs": [],
   "source": [
    "# TODO Argmax\n",
    "y_pred = XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haJ1F0EBJXZF"
   },
   "source": [
    "Utilisez la méthode `predict_classes()` de la classe `model` en passant en paramètre `test_features`. Vous devriez obtenir le même résultat que précédement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1_HK0E-JXZF"
   },
   "outputs": [],
   "source": [
    "# TODO Predict Class\n",
    "y_pred = XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YC_JNEwCJXZH"
   },
   "source": [
    "#◢  Visualisation des prédictions \n",
    "\n",
    "Méthodes utilitaires pour afficher une image et un bar chart représentant la probabilité des prédictions pour chaque chiffre de 0 à 9 (les prédictions en bleu sont les prédictions correctes et en rouge celles incorrectes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvsEAuAkJXZI"
   },
   "outputs": [],
   "source": [
    "def plot_prediction_image(predictions_array, true_label, img):\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"Chiffre prédit {} {:2.0f}% ({})\".format(predicted_label,\n",
    "                                                        np.max(predictions_array) *100,\n",
    "                                                        true_label),\n",
    "                                                        color=color)\n",
    "    \n",
    "def plot_prediction_bar_chart(predictions_array, true_label, img):\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbGBBUCuJXZK"
   },
   "source": [
    "Affichage de l'image à prédire et de la probabilité des prédictions pour chaque chiffre de 0 à 9 pour la première image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBk5rB-TJXZL"
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_prediction_image(y_proba[i], y_test[i], X_test[i])\n",
    "plt.subplot(1,2,2)\n",
    "plot_prediction_bar_chart(y_proba[i], y_test[i], X_test[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09DOSkkyJXZM"
   },
   "source": [
    "## Affichons les 20 premiers chiffres et visualisons les prédictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xill_-RbY5fP"
   },
   "outputs": [],
   "source": [
    "num_rows = 8\n",
    "num_cols = 5\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        index = num_cols * row + col\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*index+1)\n",
    "        plot_prediction_image(y_proba[index], y_test[index], X_test[index])\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*index+2)\n",
    "        plot_prediction_bar_chart(y_proba[index], y_test[index], X_test[index])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diJfR5QjJXZP"
   },
   "source": [
    "## Focus sur les images mal prédites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5bhdvkBJXZQ"
   },
   "outputs": [],
   "source": [
    "y_proba_false = y_proba[y_pred != y_test]\n",
    "y_test_false = y_test[y_pred != y_test]\n",
    "X_test_false = X_test[y_pred != y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tr5-YTIJXZS"
   },
   "outputs": [],
   "source": [
    "num_rows = 8\n",
    "num_cols = 5\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        index = num_cols * row + col\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*index+1)\n",
    "        plot_prediction_image(y_proba_false[index], y_test_false[index], X_test_false[index])\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*index+2)\n",
    "        plot_prediction_bar_chart(y_proba_false[index], y_test_false[index], X_test_false[index])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2OUWx2NuZ9V4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Keras_API.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
