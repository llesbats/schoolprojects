{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#          Réseaux de neurones: classification - Application Titanic\n",
    "\n",
    "Vous disposez d'informations sur les passagers du RSS Titanic. Trois fichiers sont fournis :\n",
    "- TrainTitanic.csv qui contient les données pour l'entraineement\n",
    "- TestTitanic.csv qui contient les données pour l'évaluation des performances du modèle\n",
    "- Gender_submission.csv qui contient les attributs de survie (labels) des individus de TestTitanic.csv\n",
    "\n",
    "Ainsi dans TrainTitanic.csv, on a une colonne \"survived\" (1 si l'individu a survecu, 0 sinon), qui n'existe pas dans TestTitanic.csv ; cette information manquante est dans Gender_submission.csv\n",
    "\n",
    "Les étapes classiques d'un projet de classification par machine learning par réseau de neurones sont: \n",
    "1. Chargement des données ; nettoyage des données ; transformation des features éventuellement (normalisation/standardisation/etc..)\n",
    "2. Définition de l'architecture du réseau de neurones - Définition du modèle Keras\n",
    "3. Choix des paramètres de l'apprentissage - Compilation du modèle Keras\n",
    "4. Apprentissage \n",
    "5. Evaluation du modèle obtenu\n",
    "6. Amélioration des performances du modèle\n",
    "7. Exploitation du modèle pour faire des prédictions (pas d'intérêt dans cette application)\n",
    "\t\n",
    "Il vous est proposé de commencer avec peu de features, d'optimiser le réseau de neurones correspondant, d'étudier l'influence de 2 ou 3 hyperparamères, puis ensuite d'augmenter le nombre de features. \n",
    "\n",
    "Vous chercherez à optimiser le réseau de neurones afin d'obtenir les meilleurs capacités prédicitves sur les individus du fichier de validation.\n",
    "\n",
    "La capacité prédictive sera mesurée par  : \n",
    "- la matrice de confusion\n",
    "- la précision, le recall, le f1 score.\n",
    "\n",
    "Le critère comparatif des performances du modèle obtenu sera choisi comme le nombre d'individus mal classés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chargement des données & Transformations initiales \n",
    "Vous récupérez les fichiers de données du Titanic : \n",
    "- Données d'entrainement : TrainTitanic.csv\n",
    "- Données de test : TestTitanic.csv + Gender_submission.csv (voir plus haut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importation de la bibliothèque pandas\n",
    "import numpy as np  #importation de la bibliothèque numpy\n",
    "\n",
    "# Chargement des données des trois fichiers dans 3 dataframes : \n",
    "# df_app, df_test et df_target\n",
    "\n",
    "# utilisation de pd.read_csv pour charger les fichiers dans les dataframes\n",
    "\n",
    "df_app    = pd.read_csv('TrainTitanic.csv',sep=\",\", decimal=\".\",engine='python')\n",
    "df_test   = pd.read_csv('TestTitanic.csv',sep=\",\", decimal=\".\",engine='python')\n",
    "df_target = pd.read_csv('Gender_submission.csv',sep=\",\", decimal=\".\",engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage des premières lignes de df_app : \n",
    "df_app.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la vue du dataset d'entrainement (est-ce pareil dans le dataset de test ?), le genre des passagers (colonnes Sex) est codé avec male et female. On va transformer cela en créant deux colonnes correspondant aux genres avec un codage 0 ou 1 selon les cas : voir get_dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  Sex_female  Sex_male  \n",
       "0      0         A/5 21171   7.2500   NaN        S           0         1  \n",
       "1      0          PC 17599  71.2833   C85        C           1         0  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S           1         0  \n",
       "3      0            113803  53.1000  C123        S           1         0  \n",
       "4      0            373450   8.0500   NaN        S           0         1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sex=pd.get_dummies(df_app.Sex,prefix=\"Sex\",prefix_sep=\"_\")\n",
    "df_app=pd.concat([df_app,X_sex], axis=1)\n",
    "df_app.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Sex_female  Sex_male  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q           0         1  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S           1         0  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q           0         1  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S           0         1  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S           1         0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FAIRE LA MEME TRANSFORMATION POUR LES DONNEES DE VALIDATION\n",
    "\n",
    "X_sex2=pd.get_dummies(df_test.Sex,prefix=\"Sex\",prefix_sep=\"_\")\n",
    "df_test=pd.concat([df_test,X_sex2], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 14)\n",
      "(418, 13)\n"
     ]
    }
   ],
   "source": [
    "# AFFICHER LA TAILLE DES DEUX DATASETS\n",
    "\n",
    "print(df_app.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'attribut de survie se trouve dans la colonne Survived de df_app (pour le set d'entrainement) et dans df_target (pour le set de test) codé sous la forme de 0 et 1. \n",
    "En classification avec un réseau de neurones, il est souvent employé un codage One-Hot.\n",
    "\n",
    "SINON SANS CODAGE ONE-HOT, COMMENT POURRAIT-ON FAIRE ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# codage One-Hot (voir to_categorical) \n",
    "target_app = to_categorical(df_app.Survived)\n",
    "target_test= to_categorical(df_target.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choix des inputs/outputs du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 5)\n",
      "(418, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch  Sex_female  Sex_male\n",
       "0       3      1      0           0         1\n",
       "1       1      1      0           1         0\n",
       "2       3      0      0           1         0\n",
       "3       1      1      0           1         0\n",
       "4       3      0      0           0         1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHOISISSEZ LES ENTREES (ou features) DU MODELE : \n",
    "# X_train pour le set d'entrainement\n",
    "# X_test  pour le set de validation\n",
    "\n",
    "X_train = df_app.copy()\n",
    "Survived = df_app.pop(\"Survived\")\n",
    "X_train = X_train.drop([\"Survived\", \"Name\", \"Sex\", \"PassengerId\", \"Fare\", \"Age\", \"Cabin\", \"Embarked\", \"Ticket\"], axis=1)\n",
    "X_test = df_test.copy()\n",
    "X_test = X_test.drop([\"Name\", \"Sex\", \"PassengerId\", \"Fare\", \"Age\", \"Cabin\", \"Embarked\", \"Ticket\"], axis=1)\n",
    "\n",
    "# AFFICHEZ LES DIMENSIONS ET LES PREMIERES LIGNES DE X_train et X_test:\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Architecture du Réseau de Neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 8)                 48        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 138\n",
      "Trainable params: 138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import des fonctions keras nécessaires\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# EN UTILISANT LES INSTRUCTIONS DU CODE INITIATIONKERAS :\n",
    "# Construction du modèle : \n",
    "# -1) initialisation : le modèle va consister en une succession de couches de neurones \n",
    "model = Sequential()\n",
    "\n",
    "# -2) choix du nombre de neurones sur couche d'entrée : n_cols\n",
    "# choix du nombre de neurones cachée sur première couche cachée: n_neurone_cache_1\n",
    "\n",
    "n_rows, n_cols = X_train.shape\n",
    "n_neurone_cache_1 = 8\n",
    "model.add(Dense(n_neurone_cache_1,\n",
    "                activation='relu',\n",
    "                input_dim=n_cols))\n",
    "\n",
    "# -3) ajout d'une couche de poids avec .add et Dense pour réseau complétement connecté: \n",
    "# - nombre de neurones cachés, \n",
    "# - type de fonction d'activation \n",
    "# - input_shape pour la couche d'entrée seulement\n",
    "# remarque: pour les fonctions de transfert :  \n",
    "# activation= 'relu' ou 'tanh' ou 'sigmoid' ou linear' ou 'softmax' etc...\n",
    "\n",
    "model.add(Dense(8,activation='relu'))\n",
    "\n",
    "# choix du nombre de neurones de sortie : n_neurone_sortie\n",
    "\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "\n",
    "# ajout d'une couche supplémentaire  \n",
    "\n",
    "\n",
    "# Résumé du modèle défini\n",
    "model.summary()\n",
    "\n",
    "# Vérifiez et confirmez le nombre de poids !!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Choix paramètres apprentissage + Compilation Réseau de Neurones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN UTILISANT LES INSTRUCTIONS DU CODE NITIATIONKERAS :\n",
    "# Compilation du réseau de neurones: \n",
    "# a minima choix de l'algo d'apprentissage, de la fonction loss, et de la métrique\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "# méthode d'optimisation: optimizer='sgd', ou 'adam' ou ... \n",
    "# fonction cout: loss='binary_crossentropy' ou 'categorical_crossentropy' ou \n",
    "# 'mean_squared_error' ou 'mean_absolute_error' etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(df_target.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Entrainement du modèle Réseau de Neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "28/28 - 0s - loss: 0.4661 - mean_squared_error: 0.1481 - val_loss: 0.2549 - val_mean_squared_error: 0.0574\n",
      "Epoch 2/15\n",
      "28/28 - 0s - loss: 0.4654 - mean_squared_error: 0.1479 - val_loss: 0.2549 - val_mean_squared_error: 0.0577\n",
      "Epoch 3/15\n",
      "28/28 - 0s - loss: 0.4641 - mean_squared_error: 0.1478 - val_loss: 0.2495 - val_mean_squared_error: 0.0565\n",
      "Epoch 4/15\n",
      "28/28 - 0s - loss: 0.4633 - mean_squared_error: 0.1472 - val_loss: 0.2522 - val_mean_squared_error: 0.0579\n",
      "Epoch 5/15\n",
      "28/28 - 0s - loss: 0.4629 - mean_squared_error: 0.1471 - val_loss: 0.2472 - val_mean_squared_error: 0.0554\n",
      "Epoch 6/15\n",
      "28/28 - 0s - loss: 0.4617 - mean_squared_error: 0.1469 - val_loss: 0.2507 - val_mean_squared_error: 0.0576\n",
      "Epoch 7/15\n",
      "28/28 - 0s - loss: 0.4607 - mean_squared_error: 0.1463 - val_loss: 0.2526 - val_mean_squared_error: 0.0583\n",
      "Epoch 8/15\n",
      "28/28 - 0s - loss: 0.4609 - mean_squared_error: 0.1461 - val_loss: 0.2487 - val_mean_squared_error: 0.0576\n",
      "Epoch 9/15\n",
      "28/28 - 0s - loss: 0.4601 - mean_squared_error: 0.1464 - val_loss: 0.2518 - val_mean_squared_error: 0.0576\n",
      "Epoch 10/15\n",
      "28/28 - 0s - loss: 0.4585 - mean_squared_error: 0.1458 - val_loss: 0.2491 - val_mean_squared_error: 0.0576\n",
      "Epoch 11/15\n",
      "28/28 - 0s - loss: 0.4589 - mean_squared_error: 0.1456 - val_loss: 0.2496 - val_mean_squared_error: 0.0576\n",
      "Epoch 12/15\n",
      "28/28 - 0s - loss: 0.4575 - mean_squared_error: 0.1453 - val_loss: 0.2508 - val_mean_squared_error: 0.0581\n",
      "Epoch 13/15\n",
      "28/28 - 0s - loss: 0.4574 - mean_squared_error: 0.1454 - val_loss: 0.2524 - val_mean_squared_error: 0.0590\n",
      "Epoch 14/15\n",
      "28/28 - 0s - loss: 0.4566 - mean_squared_error: 0.1450 - val_loss: 0.2515 - val_mean_squared_error: 0.0590\n",
      "Epoch 15/15\n",
      "28/28 - 0s - loss: 0.4562 - mean_squared_error: 0.1449 - val_loss: 0.2501 - val_mean_squared_error: 0.0583\n"
     ]
    }
   ],
   "source": [
    "# EN UTILISANT LES INSTRUCTIONS DU CODE NITIATIONKERAS :\n",
    "# Paramètres de l'entrainement : \n",
    "# - choix du nombre d'époques (epoch), \n",
    "# - de la taille du batch, \n",
    "# - de la proportion pour la validation (nombre décimal compris entre 0 et 1)\n",
    "# - du mode bavard: verbose (0 ou 1 ...)\n",
    "# - si les données sont mélangées à chaque époque (shuffle est True ou False)\n",
    "history = model.fit(X_train,\n",
    "           target_app,\n",
    "           batch_size=32,\n",
    "           epochs=15,\n",
    "           verbose=2,\n",
    "          validation_data=(X_test,target_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_app.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tracé de l'évolution de la fonction loss au cours de l'apprentissage\n",
    "# Par exemple, si vous avez créé : history = modelRN.fit((etc....) alors:\n",
    "\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Validation et visualisation des performances du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les predictions sont faites sur le set de validation finale (X_test)\n",
    "# EXPLIQUEZ CE QUI EST FAIT ICI :\n",
    "predictions_test = modelRN.predict(X_test)\n",
    "y_test=predictions_test[:,0]<predictions_test[:,1]\n",
    "y_test=y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation des performances avec : \n",
    "# - confusion_matrix\n",
    "# - classification_report\n",
    "\n",
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "\n",
    "# Matrice de confusion\n",
    "target_soluce = df_target.Survived\n",
    "print(confusion_matrix(target_soluce, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapoort de classification\n",
    "\n",
    "# support : nombre d'individus dans chaque classe\n",
    "# precision : nombre d'individus bien classés / nombre total d'individus attribués à la classe\n",
    "# recall : nombre d'individus bien classés / nombre total d'individus de la classe\n",
    "# f1-score : moyenne harmonique entre precision et recall\n",
    "print(classification_report(target_soluce, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. OPTIONNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A FAIRE UNE FOIS QUE VOUS AVEZ TROUVE VOTRE MEILLEUR MODELE\n",
    "\n",
    "# OPTION 1 : stadardisation des entrées\n",
    "# chargement de la fonction StandardScaler de la bibliothèque sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler ()\n",
    "\n",
    "# Détermination des paramètres de standardisation à partir du set d'entrainement (X_train)\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Applicattion de la standardisation aux deux sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# TESTEZ MAINTENANT SI LA STANDARDISATION A UN EFFET POSITIF SUR L'APPRENTISSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2 : EARLY STOPPING\n",
    "# ajout d'une option d'arrêt prématuré de l'entrainement pour éviter le sur-apprentissage. Par exemple:\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "# ==> si lors de l'apprentissage, on passe par un minimum de la fonction cout des données de validation \n",
    "# et qu'il n'y a pas d'amélioration pendant 5 époques alors ARRET \n",
    "\n",
    "# history = modelRN.fit(...\n",
    "#           etc...\n",
    "#           callbacks=[es]) \n",
    "\n",
    "# TESTEZ MAINTENANT L'EFFET DU EARLY STOPPING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 3 : SAUVEGARDE DES POIDS/PARAMETRES DONNANT LES MEILLEURS RESULTATS PENDANT L'ENTRAINEMENT \n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "# si options utilisées il faudra ajouter dans la fonction fit : callbacks=[es,mc]\n",
    "\n",
    "# history = modelRN.fit(...\n",
    "#           etc...\n",
    "#           callbacks=[mc]) \n",
    "\n",
    "# Pour récupérer les meilleurs résultats ainsi sauvés : \n",
    "best_modelRN = load_model('best_model.h5')\n",
    "# Calcul des prédictions avec le meilleur modèle \n",
    "best_predictions_test = best_modelRN.predict(X_test)\n",
    "best_y_test=best_predictions_test[:,0]<best_predictions_test[:,1]\n",
    "best_y_test=best_y_test.astype(int)\n",
    "\n",
    "print(confusion_matrix(target_soluce, best_y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
